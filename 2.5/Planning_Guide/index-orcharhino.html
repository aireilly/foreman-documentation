<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.18">
<title>Planning for orcharhino</title>
<link rel="stylesheet" href="./orcharhino.css">
<!-- docinfo -->
</head>
<body class="book toc2 toc-left">
    <div id="wrap">
      <script src="/js/versions.js"></script>
      <script src="/js/nav.js"></script>
      <script>
        document.open();
        document.write(buildNavigation());
        addNavbarListeners();
        document.close();
      </script>
    </div>
<div id="header">
<h1>Planning for orcharhino</h1>
<div class="details">
<span id="revnumber">version 2.1.3 (unsupported),</span>
<span id="revdate">published Dec 20 2022</span>
</div>
<div id="toc" class="toc2">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel0">
<li><a href="#part-Architecture">orcharhino Architecture</a>
<ul class="sectlevel1">
<li><a href="#chap-Red_Hat_Satellite-Architecture_Guide-Introduction_to_Red_Hat_Satellite">1. Introduction to orcharhino</a>
<ul class="sectlevel2">
<li><a href="#sect-Red_Hat_Satellite-Architecture_Guide-Introduction_to_Red_Hat_Satellite-Red_Hat_Satellite_6_System_Architecture">1.1. System Architecture</a></li>
<li><a href="#sect-Red_Hat_Satellite-Architecture_Guide-Red_Hat_Satellite_6_System_Components">1.2. System Components</a></li>
<li><a href="#Supported_Operating_Systems_and_Architectures">1.3. Supported Operating Systems and Architectures</a></li>
</ul>
</li>
<li><a href="#chap-Documentation-Architecture_Guide-Capsule_Server_Overview">2. orcharhino Proxy Overview</a>
<ul class="sectlevel2">
<li><a href="#sect-Documentation-Architecture_Guide-Capsule_Features">2.1. orcharhino Proxy Features</a></li>
<li><a href="#sect-Documentation-Architecture_Guide-Capsule_Types">2.2. orcharhino Proxy Types</a></li>
<li><a href="#sect-Documentation-Architecture_Guide-Capsule_Networking">2.3. orcharhino Proxy Networking</a></li>
</ul>
</li>
<li><a href="#chap-Red_Hat_Satellite-Architecture_Guide-Org_Loc_and_Life_Cycle_Environments">3. Organizations, Locations, and Life Cycle Environments</a>
<ul class="sectlevel2">
<li><a href="#_organizations">3.1. Organizations</a></li>
<li><a href="#_locations">3.2. Locations</a></li>
<li><a href="#_life_cycle_environments">3.3. Life Cycle Environments</a></li>
</ul>
</li>
<li><a href="#chap-Red_Hat_Satellite-Architecture_Guide-Host_Grouping_Concepts">4. Host Grouping Concepts</a>
<ul class="sectlevel2">
<li><a href="#sect-Red_Hat_Satellite-Architecture_Guide-Host_Group_Hierarchies">4.1. Host Group Structures</a></li>
</ul>
</li>
<li><a href="#chap-Red_Hat_Satellite-Architecture_Guide-Provisioning_Concepts">5. Provisioning Concepts</a>
<ul class="sectlevel2">
<li><a href="#_pxe_booting">5.1. PXE Booting</a></li>
<li><a href="#http-booting">5.2. HTTP Booting</a></li>
<li><a href="#_secure_boot">5.3. Secure Boot</a></li>
<li><a href="#_kickstart">5.4. Kickstart</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#part-Deployment_Planning">orcharhino Deployment Planning</a>
<ul class="sectlevel1">
<li><a href="#chap-Red_Hat_Satellite-Architecture_Guide-Deployment_Considerations">6. Deployment Considerations</a>
<ul class="sectlevel2">
<li><a href="#satellite_server_with_external_database">6.1. orcharhino server with External Database</a></li>
<li><a href="#sect-Mapping_the_Infrastructure_Topology">6.2. Locations and Topology</a></li>
<li><a href="#sect-Defining_Content_Sources">6.3. Content Sources</a></li>
<li><a href="#sect-Defining_the_Content_Life_Cycle">6.4. Content Life Cycle</a></li>
<li><a href="#sect-Defining_Content_Deployment">6.5. Content Deployment</a></li>
<li><a href="#sect-Automating_the_Provisioning">6.6. Provisioning</a></li>
<li><a href="#sect-Defining_Role_Based_Authentication">6.7. Role Based Authentication</a></li>
<li><a href="#sect-Additional_Tasks">6.8. Additional Tasks</a></li>
</ul>
</li>
<li><a href="#chap-Red_Hat_Satellite-Architecture_Guide-Deployment_Scenarios">7. Common Deployment Scenarios</a>
<ul class="sectlevel2">
<li><a href="#sect-Red_Hat_Satellite-Architecture_Guide-Single_Location">7.1. Single Location</a></li>
<li><a href="#sect-Red_Hat_Satellite-Architecture_Guide-Single">7.2. Single Location with Segregated Subnets</a></li>
<li><a href="#sect-Red_Hat_Satellite-Architecture_Guide-Multiple_Locations">7.3. Multiple Locations</a></li>
<li><a href="#Red_Hat_Satellite-Architecture_Guide-Capsule_with_External_Services">7.4. orcharhino Proxy with External Services</a></li>
</ul>
</li>
<li><a href="#chap-Documentation-Architecture_Guide-Required_Technical_Users">Appendix A: Technical Users Provided and Required by orcharhino</a></li>
<li><a href="#appe-Red_Hat_Satellite-Architecture_Guide-Glossary_of_Terms">Appendix B: Glossary of Terms</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<h1 id="part-Architecture" class="sect0">orcharhino Architecture</h1>
<div class="sect1">
<h2 id="chap-Red_Hat_Satellite-Architecture_Guide-Introduction_to_Red_Hat_Satellite">1. Introduction to orcharhino</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This guide contains information about features provided by the Katello plug-in.
If you do not plan to install the Katello plug-in, ignore these references.</p>
</div>
<div class="paragraph">
<p><em>orcharhino</em> is a system management solution that enables you to deploy, configure, and maintain your systems across physical, virtual, and cloud environments.
orcharhino provides provisioning, remote management and monitoring of multiple Red Hat Enterprise Linux deployments with a single, centralized tool.
<em>orcharhino Server</em> synchronizes the content from Red&#160;Hat Customer&#160;Portal and other sources, and provides functionality including fine-grained life cycle management, user and group role-based access control, integrated subscription management, as well as advanced GUI, CLI, or API access.</p>
</div>
<div class="paragraph">
<p><em>orcharhino orcharhino Proxy</em> mirrors content from orcharhino Server to facilitate content federation across various geographical locations.
Host systems can pull content and configuration from orcharhino Proxy in their location and not from the central orcharhino server.
orcharhino Proxy also provides localized services such as Puppet Master, DHCP, DNS, or TFTP.
orcharhino Proxys assist you in scaling your orcharhino environment as the number of your managed systems increases.</p>
</div>
<div class="paragraph">
<p>orcharhino Proxys decrease the load on the central server, increase redundancy, and reduce bandwidth usage.
For more information, see <a href="#chap-Documentation-Architecture_Guide-Capsule_Server_Overview">orcharhino Proxy Overview</a>.</p>
</div>
<div class="sect2">
<h3 id="sect-Red_Hat_Satellite-Architecture_Guide-Introduction_to_Red_Hat_Satellite-Red_Hat_Satellite_6_System_Architecture">1.1. System Architecture</h3>
<div class="paragraph">
<p>The following diagram represents the high-level architecture of orcharhino.</p>
</div>
<div class="paragraph">
<p>The graphics in this section are Red Hat illustrations.
Non-Red Hat illustrations are welcome.
If you want to contribute alternative images, raise a pull request in the <a href="https://github.com/theforeman/foreman-documentation">Foreman Documentation</a> GitHub page.
Note that in Red Hat terminology, "Satellite" refers to Foreman and "Capsule" refers to Smart Proxy.</p>
</div>
<div id="figu-Red_Hat_Satellite-Architecture_Guide-Red_Hat_Satellite_6_System_Architecture-Red_Hat_Satellite_6_System_Architecture" class="imageblock">
<div class="content">
<img src="images/satellite_6_system_architecture.png" alt="orcharhino System Architecture">
</div>
<div class="title">Figure 1. orcharhino System Architecture</div>
</div>
<div class="paragraph">
<p>There are four stages through which content flows in this architecture:</p>
</div>
<div id="varl-Red_Hat_Satellite-Architecture_Guide-Red_Hat_Satellite_6_System_Architecture-External_Content_Sources" class="dlist">
<dl>
<dt class="hdlist1"><strong>External Content Sources</strong></dt>
<dd>
<p>The <em>orcharhino Server</em> can consume diverse types of content from various sources.
The Red&#160;Hat Customer Portal is the primary source of software packages, errata, and container images.
In addition, you can use other supported content sources (Git repositories, Docker Hub, Puppet Forge, SCAP repositories) as well as your organization&#8217;s internal data store.</p>
</dd>
</dl>
</div>
<div id="varl-Red_Hat_Satellite-Architecture_Guide-Red_Hat_Satellite_6_System_Architecture-RednbspHat_Satellite_Server" class="dlist">
<dl>
<dt class="hdlist1"><strong>orcharhino Server</strong></dt>
<dd>
<p>The orcharhino Server enables you to plan and manage the content life cycle and the configuration of orcharhino Proxys and hosts through GUI, CLI, or API.</p>
<div class="paragraph">
<p>orcharhino server organizes the life cycle management by using organizations as principal division units.
Organizations isolate content for groups of hosts with specific requirements and administration tasks.
For example, the OS build team can use a different organization than the web development team.</p>
</div>
<div class="paragraph">
<p>orcharhino server also contains a fine-grained authentication system to provide orcharhino operators with permissions to access precisely the parts of the infrastructure that lie in their area of responsibility.</p>
</div>
</dd>
</dl>
</div>
<div id="varl-Red_Hat_Satellite-Architecture_Guide-Red_Hat_Satellite_6_System_Architecture-Capsule_Servers" class="dlist">
<dl>
<dt class="hdlist1"><strong>orcharhino Proxys</strong></dt>
<dd>
<p>orcharhino Proxys mirror content from orcharhino server to establish content sources in various geographical locations.
This enables host systems to pull content and configuration from orcharhino Proxys in their location and not from the central orcharhino server.
The recommended minimum number of orcharhino Proxys is therefore given by the number of geographic regions where the organization that uses orcharhino operates.</p>
<div class="paragraph">
<p>Using Content Views, you can specify the exact subset of content that orcharhino Proxy makes available to hosts.
See <a href="#figu-orcharhino-Architecture_Guide-orcharhino_6_System_Architecture-Content_Life_Cycle_in_orcharhino_6">[figu-orcharhino-Architecture_Guide-orcharhino_6_System_Architecture-Content_Life_Cycle_in_orcharhino_6]</a> for a closer look at life cycle management with the use of Content Views.</p>
</div>
<div class="paragraph">
<p>The communication between managed hosts and orcharhino server is routed through orcharhino Proxy that can also manage multiple services on behalf of hosts.
Many of these services use dedicated network ports, but orcharhino Proxy ensures that a single source IP address is used for all communications from the host to orcharhino server, which simplifies firewall administration.
For more information on orcharhino Proxys see <a href="#chap-Documentation-Architecture_Guide-Capsule_Server_Overview">orcharhino Proxy Overview</a>.</p>
</div>
</dd>
</dl>
</div>
<div id="varl-Red_Hat_Satellite-Architecture_Guide-Red_Hat_Satellite_6_System_Architecture-Managed_Hosts" class="dlist">
<dl>
<dt class="hdlist1"><strong>Managed Hosts</strong></dt>
<dd>
<p>Hosts are the recipients of content from orcharhino Proxys.
Hosts can be either physical or virtual.
orcharhino server can have directly managed hosts.
The base system running a orcharhino Proxy is also a managed host of orcharhino server.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>The following diagram provides a closer look at the distribution of content from orcharhino server to orcharhino Proxies.</p>
</div>
<div class="paragraph">
<p>The graphics in this section are Red Hat illustrations.
Non-Red Hat illustrations are welcome.
If you want to contribute alternative images, raise a pull request in the <a href="https://github.com/theforeman/foreman-documentation">Foreman Documentation</a> GitHub page.
Note that in Red Hat terminology, "Satellite" refers to Foreman and "Capsule" refers to Smart Proxy.</p>
</div>
<div id="figu-Red_Hat_Satellite-Architecture_Guide-Red_Hat_Satellite_6_System_Architecture-Content_Life_Cycle_in_Red_Hat_Satellite_6" class="imageblock">
<div class="content">
<img src="images/satellite_6_life_cycle.png" alt="Content Life Cycle in orcharhino">
</div>
<div class="title">Figure 2. Content Life Cycle in orcharhino</div>
</div>
<div class="paragraph">
<p>By default, each organization has a Library of content from external sources.
Content Views are subsets of content from the Library created by intelligent filtering.
You can publish and promote Content Views into life cycle environments (typically Dev, QA, and Production).
When creating a orcharhino Proxy, you can choose which life cycle environments will be copied to that orcharhino Proxy and made available to managed hosts.</p>
</div>
<div class="paragraph">
<p>Content Views can be combined to create Composite Content Views.
It can be beneficial to have a separate Content View for a repository of packages required by an operating system and a separate one for a repository of packages required by an application.
One advantage is that any updates to packages in one repository only requires republishing the relevant Content View.
You can then use Composite Content Views to combine published Content Views for ease of management.</p>
</div>
<div class="paragraph">
<p>Which Content Views should be promoted to which orcharhino Proxy depends on the orcharhino Proxy&#8217;s intended functionality.
Any orcharhino Proxy can run DNS, DHCP, and TFTP as infrastructure services that can be supplemented, for example, with content or configuration services.</p>
</div>
<div class="paragraph">
<p>You can update orcharhino Proxy by creating a new version of a Content View using synchronized content from the Library.
The new Content View version is then promoted through life cycle environments.
You can also create in-place updates of Content Views.
This means creating a minor version of the Content View in its current life cycle environment without promoting it from the Library.
For example, if you need to apply a security erratum to a Content View used in Production, you can update the Content View directly without promoting to other life cycles.
For more information on content management see the <a href="sources/usage_guides/content_management_guide.html">Content Management Guide</a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="sect-Red_Hat_Satellite-Architecture_Guide-Red_Hat_Satellite_6_System_Components">1.2. System Components</h3>
<div class="paragraph">
<p>orcharhino consists of the following open source projects:</p>
</div>
<div id="varl-Red_Hat_Satellite-Architecture_Guide-Red_Hat_Satellite_6_System_Components-Foreman" class="dlist">
<dl>
<dt class="hdlist1"><strong>Foreman</strong></dt>
<dd>
<p>Foreman is an open source application used for provisioning and life cycle management of physical and virtual systems.
Foreman automatically configures these systems using various methods, including kickstart and Puppet modules.
Foreman also provides historical data for reporting, auditing, and troubleshooting.</p>
</dd>
</dl>
</div>
<div id="varl-Red_Hat_Satellite-Architecture_Guide-Red_Hat_Satellite_6_System_Components-Katello" class="dlist">
<dl>
<dt class="hdlist1"><strong>Katello</strong></dt>
<dd>
<p>Katello is an optional Foreman plug-in for subscription and repository management.
It provides a means to subscribe to repositories and download content.
You can create and manage different versions of this content and apply them to specific systems within user-defined stages of the application life cycle.</p>
</dd>
</dl>
</div>
<div id="varl-Red_Hat_Satellite-Architecture_Guide-Red_Hat_Satellite_6_System_Components-Candlepin" class="dlist">
<dl>
<dt class="hdlist1"><strong>Candlepin</strong></dt>
<dd>
<p>Candlepin is a service within Katello that handles subscription management.</p>
</dd>
</dl>
</div>
<div id="varl-Red_Hat_Satellite-Architecture_Guide-Red_Hat_Satellite_6_System_Components-Pulp" class="dlist">
<dl>
<dt class="hdlist1"><strong>Pulp</strong></dt>
<dd>
<p>Pulp is a service within Katello that handles repository and content management.
Pulp ensures efficient storage space by not duplicating RPM packages even when requested by Content Views in different organizations.</p>
</dd>
</dl>
</div>
<div id="varl-Red_Hat_Satellite-Architecture_Guide-Red_Hat_Satellite_6_System_Components-Hammer" class="dlist">
<dl>
<dt class="hdlist1"><strong>Hammer</strong></dt>
<dd>
<p>Hammer is a CLI tool that provides command line and shell equivalents of most Web UI functions.</p>
</dd>
</dl>
</div>
<div id="varl-Red_Hat_Satellite-Architecture_Guide-Red_Hat_Satellite_6_System_Components-REST_API" class="dlist">
<dl>
<dt class="hdlist1"><strong>REST API</strong></dt>
<dd>
<p>orcharhino includes a RESTful API service that allows system administrators and developers to write custom scripts and third-party applications that interface with orcharhino.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>The terminology used in orcharhino and its components is extensive.
For explanations of frequently used terms, see <a href="#appe-orcharhino-Architecture_Guide-Glossary_of_Terms">[appe-orcharhino-Architecture_Guide-Glossary_of_Terms]</a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="Supported_Operating_Systems_and_Architectures">1.3. Supported Operating Systems and Architectures</h3>
<div class="sect3">
<h4 id="Foreman_Server_Operating_System">1.3.1. orcharhino server Operating System</h4>
<div class="paragraph">
<p>orcharhino has packages for CentOS 7 and clones, and Debian and clones.
Katello plug-in packages, which provide content management capabilities, are only available for CentOS.</p>
</div>
<div class="paragraph">
<p>The only architecture orcharhino has packages for is x86_64.</p>
</div>
</div>
<div class="sect3">
<h4 id="Client_Operating_Systems">1.3.2. Client Operating Systems</h4>
<div class="paragraph">
<p>orcharhino can help to manage any kind of operating systems that have clients orcharhino can integrate with.
For example:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Operating system installers that can perform unattended installations (such as Anaconda in Fedora and CentOS, or Debian-installer in Debian and Ubuntu)</p>
</li>
<li>
<p>Puppet</p>
</li>
<li>
<p>Ansible</p>
</li>
<li>
<p>OpenSCAP</p>
</li>
<li>
<p>OpenSSH</p>
</li>
<li>
<p>Other clients where integration is provided by external plug-ins</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>orcharhino is actively tested with the following client operating systems:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>CentOS 5, 6, 7 and 8</p>
</li>
<li>
<p>Debian stable</p>
</li>
<li>
<p>Ubuntu LTS</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The Katello plug-in provides functionality for content and subscription management.
The following utilities are provided for selected CentOS and SLES operating systems:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Katello agent</p>
</li>
<li>
<p>Subscription manager</p>
</li>
<li>
<p>Katello host tools</p>
</li>
<li>
<p>Tracer utility</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>For Red Hat family operating systems, SELinux must not be set to disabled mode.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="chap-Documentation-Architecture_Guide-Capsule_Server_Overview">2. orcharhino Proxy Overview</h2>
<div class="sectionbody">
<div class="paragraph">
<p>orcharhino Proxys provide <strong>content federation</strong> and run <strong>localized services</strong> to discover, provision, control, and configure hosts.
You can use orcharhino Proxies to extend the orcharhino deployment to various geographical locations.
This section contains an overview of features that can be enabled on orcharhino Proxies as well as their simple classification.</p>
</div>
<div class="paragraph">
<p>For more information about orcharhino Proxy requirements, installation process, and scalability considerations, see <a href="sources/installation_and_maintenance/orcharhino_proxy_installation_guide.html">Installing orcharhino Proxy</a>.</p>
</div>
<div class="sect2">
<h3 id="sect-Documentation-Architecture_Guide-Capsule_Features">2.1. orcharhino Proxy Features</h3>
<div class="paragraph">
<p>There are two sets of features provided by orcharhino Proxys.
You can use orcharhino Proxy to run services required for host management.
If you have the Katello plug-in installed, you can also configure orcharhino Proxy to mirror content from orcharhino server.</p>
</div>
<div class="paragraph">
<p>Infrastructure and host management services:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>DHCP</strong> – orcharhino Proxy can manage a DHCP server, including integration with an existing solution such as ISC DHCP servers, Active Directory, and Libvirt instances.</p>
</li>
<li>
<p><strong>DNS</strong> – orcharhino Proxy can manage a DNS server, including integration with an existing solution such as ISC BIND and Active Directory.</p>
</li>
<li>
<p><strong>TFTP</strong> – orcharhino Proxy can integrate with any UNIX-based TFTP server.</p>
</li>
<li>
<p><strong>Realm</strong> – orcharhino Proxy can manage Kerberos realms or domains so that hosts can join them automatically during provisioning.
orcharhino Proxy can integrate with an existing infrastructure, including FreeIPA and Active Directory.</p>
</li>
<li>
<p><strong>Puppet Master</strong> – orcharhino Proxy can act as a configuration management server by running Puppet Master.</p>
</li>
<li>
<p><strong>Puppet Certificate Authority</strong> – orcharhino Proxy can integrate with Puppet&#8217;s CA to provide certificates to hosts.</p>
</li>
<li>
<p><strong>Baseboard Management Controller (BMC)</strong> – orcharhino Proxy can provide power management for hosts using IPMI or Redfish.</p>
</li>
<li>
<p><strong>Provisioning template proxy</strong> – orcharhino Proxy can serve provisioning templates to hosts.</p>
</li>
<li>
<p><strong>OpenSCAP</strong> – orcharhino Proxy can perform security compliance scans on hosts.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Content related features, provided by the Katello plug-in:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Repository synchronization</strong> – the content from orcharhino server (more precisely from selected life cycle environments) is pulled to orcharhino Proxy for content delivery (enabled by Pulp).</p>
</li>
<li>
<p><strong>Content delivery</strong> – hosts configured to use orcharhino Proxy download content from that orcharhino Proxy rather than from the central orcharhino server (enabled by Pulp).</p>
</li>
<li>
<p><strong>Host action delivery</strong> – orcharhino Proxy executes scheduled actions on hosts.</p>
</li>
<li>
<p><strong>Red Hat Subscription Management (RHSM) proxy</strong> – hosts are registered to their associated orcharhino Proxys rather than to the central orcharhino server or the Red&#160;Hat Customer Portal (provided by Candlepin).</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="sect-Documentation-Architecture_Guide-Capsule_Types">2.2. orcharhino Proxy Types</h3>
<div class="paragraph">
<p>Not all orcharhino Proxy features have to be enabled at once.
You can configure a orcharhino Proxy for a specific limited purpose.
Some common configurations include:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Infrastructure orcharhino Proxies</strong> [DNS + DHCP + TFTP] – provide infrastructure services for hosts.
With provisioning template proxy enabled, infrastructure orcharhino Proxy has all necessary services for provisioning new hosts.</p>
</li>
<li>
<p><strong>Content orcharhino Proxies</strong> [Pulp] – provide content synchronized from orcharhino server to hosts.</p>
</li>
<li>
<p><strong>Configuration orcharhino Proxies</strong> [Pulp + Puppet + PuppetCA] – provide content and run configuration services for hosts.</p>
</li>
<li>
<p><strong>All-in-one orcharhino Proxies</strong> [DNS + DHCP + TFTP + Pulp + Puppet + PuppetCA] – provide a full set of orcharhino Proxy features.
All-in-one orcharhino Proxies enable host isolation by providing a single point of connection for managed hosts.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="sect-Documentation-Architecture_Guide-Capsule_Networking">2.3. orcharhino Proxy Networking</h3>
<div class="paragraph">
<p>The goal of orcharhino Proxy isolation is to provide a single endpoint for all of the host&#8217;s network communications, so that in remote network segments, you need only open firewall ports to the orcharhino Proxy itself.
The following diagram shows how the orcharhino components interact in the scenario with hosts connecting to an isolated orcharhino Proxy.</p>
</div>
<div class="paragraph">
<p>The graphics in this section are Red Hat illustrations.
Non-Red Hat illustrations are welcome.
If you want to contribute alternative images, raise a pull request in the <a href="https://github.com/theforeman/foreman-documentation">Foreman Documentation</a> GitHub page.
Note that in Red Hat terminology, "Satellite" refers to Foreman and "Capsule" refers to Smart Proxy.</p>
</div>
<div id="figu-Satellite_Topology_with_Isolated_Capsule" class="imageblock">
<div class="content">
<img src="images/satellite_6_topology_isolated.png" alt="orcharhino topology with isolated host">
</div>
<div class="title">Figure 3. orcharhino Topology with Isolated orcharhino Proxy</div>
</div>
<div class="paragraph">
<p>The following diagram shows how the orcharhino components interact when hosts connect directly to orcharhino server.
Note that as the base system of an external orcharhino Proxy is a Client of the orcharhino, this diagram is relevant even if you do not intend to have directly connected hosts.</p>
</div>
<div id="figu-Satellite_Topology_with_Internal_Capsule" class="imageblock">
<div class="content">
<img src="images/satellite_6_topology_direct.png" alt="orcharhino topology with direct host">
</div>
<div class="title">Figure 4. orcharhino Topology with Internal orcharhino Proxy</div>
</div>
<div class="paragraph">
<p>The <a href="sources/installation_and_maintenance/orcharhino_installation_guide.html#satellite-ports-and-firewalls-requirements_orcharhino">Ports and Firewalls Requirements</a> in <em>Installing orcharhino</em> and <a href="sources/installation_and_maintenance/orcharhino_proxy_installation_guide.html#capsule-ports-and-firewalls-requirements_orcharhino Proxy">Ports and Firewalls Requirements</a> in <em>Installing orcharhino Proxy</em> contain complete instructions for configuring the host-based firewall to open the ports required.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="chap-Red_Hat_Satellite-Architecture_Guide-Org_Loc_and_Life_Cycle_Environments">3. Organizations, Locations, and Life Cycle Environments</h2>
<div class="sectionbody">
<div class="paragraph">
<p>orcharhino takes a consolidated approach to Organization and Location management.
System administrators define multiple Organizations and multiple Locations in a single orcharhino server.
For example, a company might have three Organizations (Finance, Marketing, and Sales) across three countries (United States, United Kingdom, and Japan).
In this example, orcharhino server manages all Organizations across all geographical Locations, creating nine distinct contexts for managing systems.
In addition, users can define specific locations and nest them to create a hierarchy.
For example, orcharhino administrators might divide the United States into specific cities, such as Boston, Phoenix, or San Francisco.</p>
</div>
<div class="paragraph">
<p>The graphics in this section are Red Hat illustrations.
Non-Red Hat illustrations are welcome.
If you want to contribute alternative images, raise a pull request in the <a href="https://github.com/theforeman/foreman-documentation">Foreman Documentation</a> GitHub page.
Note that in Red Hat terminology, "Satellite" refers to Foreman and "Capsule" refers to Smart Proxy.</p>
</div>
<div id="figu-Example_Topology_for_Red_Hat_Satellite_6" class="imageblock">
<div class="content">
<img src="images/satellite_6_topology.png" alt="Example Topology for orcharhino">
</div>
<div class="title">Figure 5. Example Topology for orcharhino</div>
</div>
<div class="paragraph">
<p>orcharhino server defines all locations and organizations.
Each respective orcharhino orcharhino Proxy synchronizes content and handles configuration of systems in a different location.</p>
</div>
<div class="paragraph">
<p>The main orcharhino server retains the management function, while the content and configuration is synchronized between the main orcharhino server and a orcharhino orcharhino Proxy assigned to certain locations.</p>
</div>
<div class="sect2">
<h3 id="_organizations">3.1. Organizations</h3>
<div class="paragraph">
<p>Organizations divide orcharhino resources into logical groups based on ownership, purpose, content, security level, or other divisions.
You can create and manage multiple organizations through orcharhino, then divide and assign your subscriptions to each individual organization.
This provides a method of managing the content of several individual organizations under one management system.</p>
</div>
</div>
<div class="sect2">
<h3 id="_locations">3.2. Locations</h3>
<div class="paragraph">
<p>Locations divide organizations into logical groups based on geographical location.
Each location is created and used by a single account, although each account can manage multiple locations and organizations.</p>
</div>
</div>
<div class="sect2">
<h3 id="_life_cycle_environments">3.3. Life Cycle Environments</h3>
<div class="paragraph">
<p>Application life cycles are divided into <strong>life cycle environments</strong> which represent each stage of the application life cycle.
Life cycle environments are linked to form an <strong>environment path</strong>.
You can promote content along the environment path to the next life cycle environment when required.
For example, if development ends on a particular version of an application, you can promote this version to the testing environment and start development on the next version.</p>
</div>
<div class="paragraph">
<p>The graphics in this section are Red Hat illustrations.
Non-Red Hat illustrations are welcome.
If you want to contribute alternative images, raise a pull request in the <a href="https://github.com/theforeman/foreman-documentation">Foreman Documentation</a> GitHub page.
Note that in Red Hat terminology, "Satellite" refers to Foreman and "Capsule" refers to Smart Proxy.</p>
</div>
<div id="figu-An_Environment_Path_Containing_Four_Environments" class="imageblock">
<div class="content">
<img src="images/satellite_6_four_environments.png" alt="An Environment Path Containing Four Environments">
</div>
<div class="title">Figure 6. An Environment Path Containing Four Environments</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="chap-Red_Hat_Satellite-Architecture_Guide-Host_Grouping_Concepts">4. Host Grouping Concepts</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Apart from the physical topology of orcharhino Proxys, orcharhino provides several logical units for grouping hosts.
Hosts that are members of those groups inherit the group configuration.
For example, the simple parameters that define the provisioning environment can be applied at the following levels:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="nowrap">Global &gt; Organization &gt; Location &gt; Domain &gt; Host group &gt; Host</pre>
</div>
</div>
<div class="paragraph">
<p>The main logical groups in orcharhino are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Organizations</strong> – the highest level logical groups for hosts.
Organizations provide a strong separation of content and configuration.
Each organization requires a separate Subscription Manifest, and can be thought of as a separate virtual instance of a orcharhino server.
Avoid the use of organizations if a lower level host grouping is applicable.</p>
</li>
<li>
<p><strong>Locations</strong> – a grouping of hosts that should match the physical location.
Locations can be used to map the network infrastructure to prevent incorrect host placement or configuration.
For example, you cannot assign a subnet, domain, or compute resources directly to a orcharhino Proxy, only to a location.</p>
</li>
<li>
<p><strong>Host groups</strong> – the main carriers of host definitions including assigned Puppet classes, Content View, or operating system.
It is recommended to configure the majority of settings at the host group level instead of defining hosts directly.
Configuring a new host then largely becomes a matter of adding it to the right host group.
As host groups can be nested, you can create a structure that best fits your requirements (see <a href="#sect-orcharhino-Architecture_Guide-Host_Group_Hierarchies">[sect-orcharhino-Architecture_Guide-Host_Group_Hierarchies]</a>).</p>
</li>
<li>
<p><strong>Host collections</strong> – a host registered to orcharhino server for the purpose of subscription and content management is called <strong>content host</strong>.
Content hosts can be organized into host collections, which enables performing bulk actions such as package management or errata installation.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Locations and host groups can be nested, organizations and host collections are flat.</p>
</div>
<div class="sect2">
<h3 id="sect-Red_Hat_Satellite-Architecture_Guide-Host_Group_Hierarchies">4.1. Host Group Structures</h3>
<div class="paragraph">
<p>The fact that host groups can be nested to inherit parameters from each other allows for designing host group hierarchies that fit particular workflows.
A well planned host group structure can help to simplify the maintenance of host settings.
This section outlines four approaches to organizing host groups.</p>
</div>
<div id="figu-Life_Cycle_Environment_Based_Structure" class="imageblock">
<div class="content">
<img src="images/satellite_6_host_group_structures.png" alt="Host Group Structuring Examples">
</div>
<div class="title">Figure 7. Host Group Structuring Examples</div>
</div>
<div id="brid-Flat_Structure" class="paragraph">
<p><strong>Flat Structure</strong></p>
</div>
<div class="paragraph">
<p>The advantage of a flat structure is limited complexity, as inheritance is avoided.
In a deployment with few host types, this scenario is the best option.
However, without inheritance there is a risk of high duplication of settings between host groups.</p>
</div>
<div id="brid-Life_Cycle_Environment_Based_Structure" class="paragraph">
<p><strong>Life Cycle Environment Based Structure</strong></p>
</div>
<div class="paragraph">
<p>In this hierarchy, the first host group level is reserved for parameters specific to a life cycle environment.
The second level contains operating system related definitions, and the third level contains application specific settings.
Such structure is useful in scenarios where responsibilities are divided among life cycle environments (for example, a dedicated owner for the <strong>Development</strong>, <strong>QA</strong>, and <strong>Production</strong> life cycle stages).</p>
</div>
<div id="brid-Flat_Host_Group_Structure" class="paragraph">
<p><strong>Application Based Structure</strong></p>
</div>
<div class="paragraph">
<p>This hierarchy is based on roles of hosts in a specific application.
For example, it enables defining network settings for groups of back-end and front-end servers.
The selected characteristics of hosts are segregated, which supports Puppet-focused management of complex configurations.
However, the content views can only be assigned to host groups at the bottom level of this hierarchy.</p>
</div>
<div id="brid-Location_Based_Structure" class="paragraph">
<p><strong>Location Based Structure</strong></p>
</div>
<div class="paragraph">
<p>In this hierarchy, the distribution of locations is aligned with the host group structure.
In a scenario where the location (orcharhino Proxy) topology determines many other attributes, this approach is the best option.
On the other hand, this structure complicates sharing parameters across locations, therefore in complex environments with a large number of applications, the number of host group changes required for each configuration change increases significantly.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="chap-Red_Hat_Satellite-Architecture_Guide-Provisioning_Concepts">5. Provisioning Concepts</h2>
<div class="sectionbody">
<div class="paragraph">
<p>An important feature of orcharhino is unattended provisioning of hosts.
To achieve this, orcharhino uses DNS and DHCP infrastructures, PXE booting, TFTP, and Kickstart.
Use this chapter to understand the working principle of these concepts.</p>
</div>
<div class="sect2">
<h3 id="_pxe_booting">5.1. PXE Booting</h3>
<div class="paragraph">
<p>Preboot execution environment (PXE) provides the ability to boot a system over a network.
Instead of using local hard drives or a CD-ROM, PXE uses DHCP to provide host with standard information about the network, to discover a TFTP server, and to download a boot image.</p>
</div>
<div class="sect3">
<h4 id="_pxe_sequence">5.1.1. PXE Sequence</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The host boots the PXE image if no other bootable image is found.</p>
</li>
<li>
<p>A NIC of the host sends a broadcast request to the DHCP server.</p>
</li>
<li>
<p>The DHCP server receives the request and sends standard information about the network: IP address, subnet mask, gateway, DNS, the location of a TFTP server, and a boot image.</p>
</li>
<li>
<p>The host obtains the boot loader <code>image/pxelinux.0</code> and the configuration file <code>pxelinux.cfg/00:MA:CA:AD:D</code> from the TFTP server.</p>
</li>
<li>
<p>The host configuration specifies the location of a kernel image, <code>initrd</code> and Kickstart.</p>
</li>
<li>
<p>The host downloads the files and installs the image.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>For an example of using PXE Booting by orcharhino server, see <a href="https://docs.theforeman.org/2.5/Provisioning_Guide/index-foreman-el.html#provisioning-workflow_provisioning">Provisioning Workflow</a> in the <em>Provisioning Guide</em>.</p>
</div>
</div>
<div class="sect3">
<h4 id="_pxe_booting_requirements">5.1.2. PXE Booting Requirements</h4>
<div class="paragraph">
<p>To provision machines using PXE booting, ensure that you meet the following requirements:</p>
</div>
<div class="ulist">
<div class="title">Network requirements</div>
<ul>
<li>
<p>Optional: If the host and the DHCP server are separated by a router, configure the DHCP relay agent and point to the DHCP server.</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Client requirements</div>
<ul>
<li>
<p>Ensure that all the network-based firewalls are configured to allow clients on the subnet to access the orcharhino Proxy.
For more information, see <a href="#figu-Satellite_Topology_with_Isolated_Capsule">orcharhino Topology with Isolated orcharhino Proxy</a>.</p>
</li>
<li>
<p>Ensure that your client has access to the DHCP and TFTP servers.</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">orcharhino requirements</div>
<ul>
<li>
<p>Ensure that both orcharhino server and orcharhino Proxy have DNS configured and are able to resolve provisioned host names.</p>
</li>
<li>
<p>Ensure that the UDP ports 67 and 68 are accessible by the client to enable the client to receive a DHCP offer with the boot options.</p>
</li>
<li>
<p>Ensure that the UDP port 69 is accessible by the client so that the client can access the TFTP server on the orcharhino Proxy.</p>
</li>
<li>
<p>Ensure that the TCP port 80 is accessible by the client to allow the client to download files and Kickstart templates from the orcharhino Proxy.</p>
</li>
<li>
<p>Ensure that the host provisioning interface subnet has a DHCP orcharhino Proxy set.</p>
</li>
<li>
<p>Ensure that the host provisioning interface subnet has a TFTP orcharhino Proxy set.</p>
</li>
<li>
<p>Ensure that the host provisioning interface subnet has a Templates orcharhino Proxy set.</p>
</li>
<li>
<p>Ensure that DHCP with the correct subnet is enabled using the orcharhino installer.</p>
</li>
<li>
<p>Enable TFTP using the orcharhino installer.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="http-booting">5.2. HTTP Booting</h3>
<div class="paragraph">
<p>You can use HTTP booting to boot systems over a network using HTTP.</p>
</div>
<div class="sect3">
<h4 id="http-booting-requirements">5.2.1. HTTP Booting Requirements with managed DHCP</h4>
<div class="paragraph">
<p>To provision machines through HTTP booting ensure that you meet the following requirements:</p>
</div>
<div class="paragraph">
<div class="title">Client requirements</div>
<p>For HTTP booting to work, ensure that your environment has the following client-side configurations:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>All the network-based firewalls are configured to allow clients on the subnet to access the orcharhino Proxy.
For more information, see <a href="#figu-Satellite_Topology_with_Isolated_Capsule">orcharhino Topology with Isolated orcharhino Proxy</a>.</p>
</li>
<li>
<p>Your client has access to the DHCP and DNS servers.</p>
</li>
<li>
<p>Your client has access to the HTTP UEFI Boot orcharhino Proxy.</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Network requirements</div>
<ul>
<li>
<p>Optional: If the host and the DHCP server are separated by a router, configure the DHCP relay agent and point to the DHCP server.</p>
</li>
</ul>
</div>
<div class="paragraph">
<div class="title">orcharhino requirements</div>
<p>Although TFTP protocol is not used for HTTP UEFI Booting, orcharhino uses TFTP orcharhino Proxy API to deploy bootloader configuration.</p>
</div>
<div class="paragraph">
<p>For HTTP booting to work, ensure that orcharhino has the following configurations:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Both orcharhino server and orcharhino Proxy have DNS configured and are able to resolve provisioned host names.</p>
</li>
<li>
<p>The UDP ports 67 and 68 are accessible by the client so that the client can send and receive a DHCP request and offer.</p>
</li>
<li>
<p>Ensure that the TCP port 8000 is open for the client to download the bootloader and Kickstart templates from the orcharhino Proxy.</p>
</li>
<li>
<p>The TCP port 8443 is open for the client to download the bootloader from the orcharhino Proxy using the HTTPS protocol.</p>
</li>
<li>
<p>The subnet that functions as the host&#8217;s provisioning interface has a DHCP orcharhino Proxy, a HTTP Boot orcharhino Proxy,  a TFTP orcharhino Proxy, and a Templates orcharhino Proxy</p>
</li>
<li>
<p>The  <code>grub2-efi</code> package is updated to the latest version. To update the <code>grub2-efi</code> package to the latest version and execute the installer to copy the recent bootloader from <code>/boot</code> into <code>/var/lib/tftpboot</code> directory, enter the following commands:</p>
<div class="listingblock">
<div class="content">
<pre class="nowrap"># yum install grub2-efi
# foreman-installer</pre>
</div>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_http_booting_requirements_with_unmanaged_dhcp">5.2.2. HTTP Booting Requirements with unmanaged DHCP</h4>
<div class="paragraph">
<p>To provision machines through HTTP booting without managed DHCP ensure that you meet the following requirements:</p>
</div>
<div class="ulist">
<div class="title">Client requirements</div>
<ul>
<li>
<p>HTTP UEFI Boot URL must be set to one of:</p>
<div class="ulist">
<ul>
<li>
<p><code>http://{smartproxy.example.com}:8000</code></p>
</li>
<li>
<p><code>https://{smartproxy.example.com}:8443</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Ensure that your client has access to the DHCP and DNS servers.</p>
</li>
<li>
<p>Ensure that your client has access to the HTTP UEFI Boot orcharhino Proxy.</p>
</li>
<li>
<p>Ensure that all the network-based firewalls are configured to allow clients on the subnet to access the orcharhino Proxy.
For more information, see <a href="#figu-Satellite_Topology_with_Isolated_Capsule">orcharhino Topology with Isolated orcharhino Proxy</a>.</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Network requirements</div>
<ul>
<li>
<p>An unmanaged DHCP server available for clients.</p>
</li>
<li>
<p>An unmanaged DNS server available for clients. In case DNS is not available, use IP address to configure clients.</p>
</li>
</ul>
</div>
<div class="paragraph">
<div class="title">orcharhino requirements</div>
<p>Although TFTP protocol is not used for HTTP UEFI Booting, orcharhino use TFTP orcharhino Proxy API to deploy bootloader configuration.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Ensure that both orcharhino server and orcharhino Proxy have DNS configured and are able to resolve provisioned host names.</p>
</li>
<li>
<p>Ensure that the UDP ports 67 and 68 are accessible by the client so that the client can send and receive a DHCP request and offer.</p>
</li>
<li>
<p>Ensure that the TCP port 8000 is open for the client to download bootloader and Kickstart templates from the orcharhino Proxy.</p>
</li>
<li>
<p>Ensure that the TCP port 8443 is open for the client to download the bootloader from the orcharhino Proxy via HTTPS protocol.</p>
</li>
<li>
<p>Ensure that the host provisioning interface subnet has a HTTP Boot orcharhino Proxy set.</p>
</li>
<li>
<p>Ensure that the host provisioning interface subnet has a TFTP orcharhino Proxy set.</p>
</li>
<li>
<p>Ensure that the host provisioning interface subnet has a Templates orcharhino Proxy set.</p>
</li>
<li>
<p>Update the <code>grub2-efi</code> package to the latest version and execute the installer to copy the recent bootloader from the <code>/boot</code> directory into the <code>/var/lib/tftpboot</code> directory:</p>
<div class="listingblock">
<div class="content">
<pre class="nowrap"># yum install grub2-efi
# foreman-installer</pre>
</div>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_secure_boot">5.3. Secure Boot</h3>
<div class="paragraph">
<p>When orcharhino is installed on Red Hat Enterprise Linux or compatible operating systems using  <code>foreman-installer</code>, grub2 and shim bootloaders that are signed by Red Hat are deployed into the TFTP and HTTP UEFI Boot directory. PXE loader options named "SecureBoot" configure hosts to load <code>shim.efi</code>.</p>
</div>
<div class="paragraph">
<p>On Debian and Ubuntu operating systems, the grub2 bootloader is created using the <code>grub2-mkimage</code> unsigned. To perform the Secure Boot, the bootloader must be manually signed and key enrolled into the EFI firmware. Alternatively, grub2 from Ubuntu or Red Hat Enterprise Linux can be copied to perform booting.</p>
</div>
<div class="paragraph">
<p>Grub2 in Red Hat Enterprise Linux 8.0-8.3 were updated to mitigate [Boot Hole Vulnerability](<a href="https://access.redhat.com/security/vulnerabilities/grub2bootloader" class="bare">https://access.redhat.com/security/vulnerabilities/grub2bootloader</a>) and keys of existing Red Hat Enterprise Linux kernels were invalidated. To boot any of the affected Red Hat Enterprise Linux kernel (or OS installer), you must enroll keys manually into the EFI firmware for each host:</p>
</div>
<div class="paragraph">
<p>+</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="nowrap"># pesign -P -h -i /boot/vmlinuz-&lt;version&gt;
# mokutil --import-hash &lt;hash value returned from pesign&gt;
# reboot</pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_kickstart">5.4. Kickstart</h3>
<div class="paragraph">
<p>You can use Kickstart to automate the installation process of a orcharhino or orcharhino Proxy by creating a Kickstart file that contains all the information that is required for the installation.
For more information about Kickstart, see <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/installation_guide/chap-kickstart-installations">Kickstart Installations</a> in the <em>Red Hat Enterprise Linux 7 Installation Guide</em>.</p>
</div>
<div class="sect3">
<h4 id="_workflow">5.4.1. Workflow</h4>
<div class="paragraph">
<p>When you run a orcharhino Kickstart script, the following workflow occurs:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>It specifies the installation location of a orcharhino server or a orcharhino Proxy.</p>
</li>
<li>
<p>It installs the predefined packages.</p>
</li>
<li>
<p>It installs Red&#160;Hat Subscription Manager.</p>
</li>
<li>
<p>It uses Activation Keys to subscribe the hosts to orcharhino.</p>
</li>
<li>
<p>It installs Puppet, and configures a <code>puppet.conf</code> file to indicate the orcharhino or orcharhino Proxy instance.</p>
</li>
<li>
<p>It enables Puppet to run and request a certificate.</p>
</li>
<li>
<p>It runs user defined snippets.</p>
</li>
</ol>
</div>
</div>
</div>
</div>
</div>
<h1 id="part-Deployment_Planning" class="sect0">orcharhino Deployment Planning</h1>
<div class="sect1">
<h2 id="chap-Red_Hat_Satellite-Architecture_Guide-Deployment_Considerations">6. Deployment Considerations</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This section provides an overview of general topics to be considered when planning a orcharhino deployment together with recommendations and references to more specific documentation.</p>
</div>
<div class="sect2">
<h3 id="satellite_server_with_external_database">6.1. orcharhino server with External Database</h3>
<div class="paragraph">
<p>When you install orcharhino, the <code>foreman-installer</code> command creates databases on the same server that you install orcharhino.
Depending on your requirements, moving to external databases can provide increased working memory for orcharhino, which can improve response times for database operating requests.
Moving to external databases distributes the workload and can increase the capacity for performance tuning.</p>
</div>
<div class="paragraph">
<p>Consider using external databases if you plan to use your orcharhino deployment for the following scenarios:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Frequent remote execution tasks.
This creates a high volume of records in PostgreSQL and generates heavy database workloads.</p>
</li>
<li>
<p>High disk I/O workloads from frequent repository synchronization or Content View publishing.
This causes orcharhino to create a record in PostgreSQL for each job.</p>
</li>
<li>
<p>High volume of hosts.</p>
</li>
<li>
<p>High volume of synced content.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>For more information about using an external database, see <a href="sources/installation_and_maintenance/orcharhino_installation_guide.html#using-external-databases_orcharhino">Using External Databases with orcharhino</a> in <em>Installing orcharhino</em>.</p>
</div>
</div>
<div class="sect2">
<h3 id="sect-Mapping_the_Infrastructure_Topology">6.2. Locations and Topology</h3>
<div class="paragraph">
<p>This section outlines general considerations that should help you to specify your orcharhino deployment scenario.
The most common deployment scenarios are listed in <a href="#chap-orcharhino-Architecture_Guide-Deployment_Scenarios">[chap-orcharhino-Architecture_Guide-Deployment_Scenarios]</a>.
The defining questions are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>How many orcharhino Proxys do I need?</strong> – The number of geographic locations where your organization operates should translate to the number of orcharhino Proxys.
By assigning a orcharhino Proxy to each location, you decrease the load on orcharhino server, increase redundancy, and reduce bandwidth usage.
orcharhino server itself can act as a orcharhino Proxy (it contains an integrated orcharhino Proxy by default).
This can be used in single location deployments and to provision the base system&#8217;s of orcharhino Proxys.
Using the integrated orcharhino Proxy to communicate with hosts in remote locations is not recommended as it can lead to suboptimal network utilization.</p>
</li>
<li>
<p><strong>What services will be provided by orcharhino Proxys?</strong> – After establishing the number of orcharhino Proxies, decide what services will be enabled on each orcharhino Proxy.
Even though the whole stack of content and configuration management capabilities is available, some infrastructure services (DNS, DHCP, TFTP) can be outside of a orcharhino administrator&#8217;s control.
In such case, orcharhino Proxies have to integrate with those external services (see <a href="#orcharhino-Architecture_Guide-Capsule_with_External_Services">[orcharhino-Architecture_Guide-Capsule_with_External_Services]</a>).</p>
</li>
<li>
<p><strong>What compute resources do I need for my hosts?</strong> – Apart from provisioning bare metal hosts, you can use various compute resources supported by orcharhino.
To learn about provisioning on different compute resources see the <a href="https://docs.theforeman.org/2.5/Provisioning_Guide/index-foreman-el.html#"><em>Provisioning Guide</em></a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="sect-Defining_Content_Sources">6.3. Content Sources</h3>
<div class="paragraph">
<p>The Subscription Manifest determines what Red&#160;Hat repositories are accessible from your orcharhino server.
Once you enable a Red&#160;Hat repository, an associated orcharhino Product is created automatically.
For distributing content from custom sources you need to create products and repositories manually.
Red&#160;Hat repositories are signed with GPG keys by default, and it is recommended to create GPG keys also for your custom repositories.
The configuration of custom repositories depends on the type of content they hold (RPM packages, or Docker images).</p>
</div>
<div class="paragraph">
<p>Repositories configured as <code>yum</code> repositories, that contain only RPM packages, can make use of the new download policy setting to save on synchronization time and storage space.
This setting enables selecting from <strong>Immediate</strong> and <strong>On demand</strong>.
The <strong>On demand</strong> setting saves space and time by only downloading packages when requested by clients.
For detailed instructions on setting up content sources see <a href="sources/usage_guides/content_management_guide.html#Importing_Content">Importing Content</a> in the <em>Content Management Guide</em>.</p>
</div>
<div class="paragraph">
<p>A custom repository within orcharhino server is in most cases populated with content from an external staging server.
Such servers lie outside of the orcharhino infrastructure, however, it is recommended to use a revision control system (such as Git) on these servers to have better control over the custom content.</p>
</div>
</div>
<div class="sect2">
<h3 id="sect-Defining_the_Content_Life_Cycle">6.4. Content Life Cycle</h3>
<div class="paragraph">
<p>orcharhino provides features for precise management of the content life cycle.
A <strong>life cycle environment</strong> represents a stage in the content life cycle, a <strong>Content View</strong> is a filtered set of content, and can be considered as a defined subset of content.
By associating Content Views with life cycle environments, you make content available to hosts in a defined way (see <a href="#figu-orcharhino-Architecture_Guide-orcharhino_6_System_Architecture-Content_Life_Cycle_in_orcharhino_6">[figu-orcharhino-Architecture_Guide-orcharhino_6_System_Architecture-Content_Life_Cycle_in_orcharhino_6]</a> for visualization of the process).
For a detailed overview of the content management process see <a href="sources/usage_guides/content_management_guide.html#Importing_Custom_Content">Importing Custom Content</a> in the <em>Content Management Guide</em>.
The following section provides general scenarios for deploying content views as well as life cycle environments.</p>
</div>
<div class="paragraph">
<p>The default life cycle environment called <strong>Library</strong> gathers content from all connected sources.
It is not recommended to associate hosts directly with the Library as it prevents any testing of content before making it available to hosts.
Instead, create a life cycle environment path that suits your content workflow.
The following scenarios are common:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>A single life cycle environment</strong> – content from Library is promoted directly to the production stage.
This approach limits the complexity but still allows for testing the content within the Library before making it available to hosts.</p>
<div class="paragraph">
<p><span class="image"><img src="images/lc_path-basic.png" alt="A single life cycle environment"></span></p>
</div>
</li>
<li>
<p><strong>A single life cycle environment path</strong> – both operating system and applications content is promoted through the same path.
The path can consist of several stages (for example <strong>Development</strong>, <strong>QA</strong>, <strong>Production</strong>), which enables thorough testing but requires additional effort.</p>
<div class="paragraph">
<p><span class="image"><img src="images/lc_path-simple.png" alt="A single life cycle environment path"></span></p>
</div>
</li>
<li>
<p><strong>Application specific life cycle environment paths</strong> – each application has a separate path, which allows for individual application release cycles.
You can associate specific compute resources with application life cycle stages to facilitate testing.
On the other hand, this scenario increases the maintenance complexity.</p>
<div class="paragraph">
<p><span class="image"><img src="images/lc_path-diverged.png" alt="Application specific life cycle environment paths"></span></p>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>The following content view scenarios are common:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>All in one content view</strong> – a content view that contains all necessary content for the majority of your hosts.
Reducing the number of content views is an advantage in deployments with constrained resources (time, storage space) or with uniform host types.
However, this scenario limits the content view capabilities such as time based snapshots or intelligent filtering.
Any change in content sources affects a proportion of hosts.</p>
</li>
<li>
<p><strong>Host specific content view</strong> – a dedicated content view for each host type.
This approach can be useful in deployments with a small number of host types (up to 30).
However, it prevents sharing content across host types as well as separation based on criteria other than the host type (for example between operating system and applications).
With critical updates every content view has to be updated, which increases maintenance efforts.</p>
</li>
<li>
<p><strong>Host specific composite content view</strong> – a dedicated combination of content views for each host type.
This approach enables separating host specific and shared content, for example you can have dedicated content views for the operating system and application content.
By using a composite, you can manage your operating system and applications separately and at different frequencies.</p>
</li>
<li>
<p><strong>Component based content view</strong> – a dedicated content view for a specific application.
For example a database content view can be included into several composite content views.
This approach allows for greater standardization but it leads to an increased number of content views.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The optimal solution depends on the nature of your host environment.
Avoid creating a large number of content views, but keep in mind that the size of a content view affects the speed of related operations (publishing, promoting).
Also make sure that when creating a subset of packages for the content view, all dependencies are included as well.
Note that kickstart repositories should not be added to content views, as they are used for host provisioning only.</p>
</div>
</div>
<div class="sect2">
<h3 id="sect-Defining_Content_Deployment">6.5. Content Deployment</h3>
<div class="paragraph">
<p>Content deployment is the management of errata and packages on content hosts.
There are two methods for content deployment on orcharhino; the default is <strong>remote execution</strong>, and the second is the deprecated <strong>katello agent</strong>.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Remote execution</strong> - Remote execution via SSH transport allows the install, update, or removal of packages, the bootstrap of configuration management agents, and the trigger of Puppet runs.
This is the preferred method for content deployment.</p>
<div class="paragraph">
<p>While orcharhino server has remote execution enabled by default, it is disabled by default on orcharhino Proxys and content hosts and has to be manually enabled.</p>
</div>
</li>
<li>
<p><strong>Katello agent</strong> - Uses the <strong>goferd</strong> service which communicates to and from the orcharhino server and is primarily tasked with installing and updating packages.
It is enabled and started automatically on content hosts after successfully installing the <strong>katello-agent</strong> package.</p>
<div class="paragraph">
<p>Note that the Katello agent is deprecated and will be removed in a future orcharhino version.</p>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="sect-Automating_the_Provisioning">6.6. Provisioning</h3>
<div class="paragraph">
<p>orcharhino provides several features to help you automate the host provisioning, including provisioning templates, configuration management with Puppet, and host groups for standardized provisioning of host roles.
For a description of the provisioning workflow see <a href="https://docs.theforeman.org/2.5/Provisioning_Guide/index-foreman-el.html#provisioning-workflow_provisioning">Provisioning Workflow</a> in the <em>Provisioning Guide</em>.
The same guide contains instructions for provisioning on various compute resources.</p>
</div>
</div>
<div class="sect2">
<h3 id="sect-Defining_Role_Based_Authentication">6.7. Role Based Authentication</h3>
<div class="paragraph">
<p>Assigning a role to a user enables controlling access to orcharhino components based on a set of permissions.
You can think of role based authentication as a way of hiding unnecessary objects from users who are not supposed to interact with them.</p>
</div>
<div class="paragraph">
<p>There are various criteria for distinguishing among different roles within an organization.
Apart from the administrator role, the following types are common:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Roles related to applications or parts of infrastructure</strong> – for example, roles for owners of Red Hat Enterprise Linux as the operating system versus owners of application servers and database servers.</p>
</li>
<li>
<p><strong>Roles related to a particular stage of the software life cycle</strong> – for example, roles divided among the development, testing, and production phases, where each phase has one or more owners.</p>
</li>
<li>
<p><strong>Roles related to specific tasks</strong> – such as security manager or license manager.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When defining a custom role, consider the following recommendations:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Define the expected tasks and responsibilities</strong> – define the subset of the orcharhino infrastructure that will be accessible to the role as well as actions permitted on this subset.
Think of the responsibilities of the role and how it would differ from other roles.</p>
</li>
<li>
<p><strong>Use predefined roles whenever possible</strong> – orcharhino provides a number of sample roles that can be used alone or as part of a role combination.
Copying and editing an existing role can be a good start for creating a custom role.</p>
</li>
<li>
<p><strong>Consider all affected entities</strong> – for example, a content view promotion automatically creates new Puppet Environments for the particular life cycle environment and content view combination.
Therefore, if a role is expected to promote content views, it also needs permissions to create and edit Puppet Environments.</p>
</li>
<li>
<p><strong>Consider areas of interest</strong> – even though a role has a limited area of responsibility, there might be a wider area of interest.
Therefore, you can grant the role a read only access to parts of orcharhino infrastructure that influence its area of responsibility.
This allows users to get earlier access to information about potential upcoming changes.</p>
</li>
<li>
<p><strong>Add permissions step by step</strong> – test your custom role to make sure it works as intended.
A good approach in case of problems is to start with a limited set of permissions, add permissions step by step, and test continuously.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>For instructions on defining roles and assigning them to users, see <a href="sources/management_ui/the_administer_menu.html#chap-Administering-Users_and_Roles">Managing Users and Roles</a> in the <em>Administering orcharhino</em> guide.
The same guide contains information on configuring external authentication sources.</p>
</div>
</div>
<div class="sect2">
<h3 id="sect-Additional_Tasks">6.8. Additional Tasks</h3>
<div class="paragraph">
<p>This section provides a short overview of selected orcharhino capabilities that can be used for automating certain tasks or extending the core usage of orcharhino:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Discovering bare metal hosts</strong> – the orcharhino Discovery plug-in enables automatic bare-metal discovery of unknown hosts on the provisioning network.
These new hosts register themselves to orcharhino server and the Puppet Agent on the client uploads system facts collected by Facter, such as serial ID, network interface, memory, and disk information.
After registration you can initialize provisioning of those discovered hosts.
For details, see <a href="https://docs.theforeman.org/2.5/Provisioning_Guide/index-foreman-el.html#creating-hosts-from-discovered-hosts">Creating Hosts from Discovered Hosts</a> in the <em>Provisioning Guide</em>.</p>
</li>
<li>
<p><strong>Backup management</strong> – backup and disaster recovery instructions, see <a href="sources/management_ui/the_administer_menu.html#backing-up-satellite-server-and-capsule-server">Backing Up orcharhino server and orcharhino Proxy</a> in <em>Administering orcharhino</em>.
Using remote execution, you can also configure recurring backup tasks on managed hosts.
For more information on remote execution see <a href="sources/management_ui/the_hosts_menu.html#configuring-and-setting-up-remote-jobs_managing-hosts">Configuring and Setting up Remote Jobs</a> in <em>Managing Hosts</em>.</p>
</li>
<li>
<p><strong>Security management</strong> – orcharhino supports security management in various ways, including update and errata management, OpenSCAP integration for system verification, update and security compliance reporting, and fine grained role based authentication.
Find more information on errata management and OpenSCAP concepts in <a href="sources/management_ui/the_hosts_menu.html"><em>Managing Hosts</em></a>.</p>
</li>
<li>
<p><strong>Incident management</strong> – orcharhino supports the incident management process by providing a centralized overview of all systems including reporting and email notifications.
Detailed information on each host is accessible from orcharhino server, including the event history of recent changes.</p>
</li>
<li>
<p><strong>Scripting with Hammer and API</strong> – orcharhino provides a command line tool called Hammer that provides a CLI equivalent to the majority of web UI procedures.
In addition, you can use the access to the orcharhino API to write automation scripts in a selected programming language.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="chap-Red_Hat_Satellite-Architecture_Guide-Deployment_Scenarios">7. Common Deployment Scenarios</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This section provides a brief overview of common deployment scenarios for orcharhino.
Note that many variations and combinations of the following layouts are possible.</p>
</div>
<div class="sect2">
<h3 id="sect-Red_Hat_Satellite-Architecture_Guide-Single_Location">7.1. Single Location</h3>
<div class="paragraph">
<p>An <em>integrated orcharhino Proxy</em> is a virtual orcharhino Proxy that is created by default in orcharhino server during the installation process.
This means orcharhino server can be used to provision directly connected hosts for orcharhino deployment in a single geographical location, therefore only one physical server is needed.
The base systems of isolated orcharhino Proxies can be directly managed by orcharhino server, however it is not recommended to use this layout to manage other hosts in remote locations.</p>
</div>
</div>
<div class="sect2">
<h3 id="sect-Red_Hat_Satellite-Architecture_Guide-Single">7.2. Single Location with Segregated Subnets</h3>
<div class="paragraph">
<p>Your infrastructure might require multiple isolated subnets even if orcharhino is deployed in a single geographic location.
This can be achieved for example by deploying multiple orcharhino Proxys with DHCP and DNS services, but the recommended way is to create segregated subnets using a single orcharhino Proxy.
This orcharhino Proxy is then used to manage hosts and compute resources in those segregated networks to ensure they only have to access the orcharhino Proxy for provisioning, configuration, errata, and general management.
For more information on configuring subnets see <a href="sources/management_ui/the_hosts_menu.html"><em>Managing Hosts</em></a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="sect-Red_Hat_Satellite-Architecture_Guide-Multiple_Locations">7.3. Multiple Locations</h3>
<div class="paragraph">
<p>It is recommended to create at least one orcharhino Proxy per geographic location.
This practice can save bandwidth since hosts obtain content from a local orcharhino Proxy.
Synchronization of content from remote repositories is done only by the orcharhino Proxy, not by each host in a location.
In addition, this layout makes the provisioning infrastructure more reliable and easier to configure.
See <a href="#figu-orcharhino-Architecture_Guide-orcharhino_6_System_Architecture-orcharhino_6_System_Architecture">[figu-orcharhino-Architecture_Guide-orcharhino_6_System_Architecture-orcharhino_6_System_Architecture]</a> for an illustration of this approach.</p>
</div>
</div>
<div class="sect2">
<h3 id="Red_Hat_Satellite-Architecture_Guide-Capsule_with_External_Services">7.4. orcharhino Proxy with External Services</h3>
<div class="paragraph">
<p>You can configure a orcharhino Proxy (integrated or standalone) to use external DNS, DHCP, or TFTP service.
If you already have a server that provides these services in your environment, you can integrate it with your orcharhino deployment.
For information about how to configure a orcharhino Proxy with external services, see <a href="sources/installation_and_maintenance/orcharhino_proxy_installation_guide.html#configuring-external-services">Configuring orcharhino Proxy with External Services</a> in <em>Installing orcharhino Proxy</em>.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="chap-Documentation-Architecture_Guide-Required_Technical_Users">Appendix A: Technical Users Provided and Required by orcharhino</h2>
<div class="sectionbody">
<div class="paragraph">
<p>During the installation of orcharhino, system accounts are created.
They are used to manage files and process ownership of the components integrated into orcharhino.
Some of these accounts have fixed UIDs and GIDs, while others take the next available UID and GID on the system instead.
To control the UIDs and GIDs assigned to accounts, you can define accounts before installing orcharhino.
Because some of the accounts have hard-coded UIDs and GIDs, it is not possible to do this with all accounts created during orcharhino installation.</p>
</div>
<div class="paragraph">
<p>The following table lists all the accounts created by orcharhino during installation.
You can predefine accounts that have <strong>Yes</strong> in the <strong>Flexible UID and GID</strong> column with custom UID and GID before installing orcharhino.</p>
</div>
<div class="paragraph">
<p>Do not change the home and shell directories of system accounts because they are requirements for orcharhino to work correctly.</p>
</div>
<div class="paragraph">
<p>Because of potential conflicts with local users that orcharhino creates, you cannot use external identity providers for the system users of the orcharhino base operating system.</p>
</div>
<table id="tabl-Documentation-Architecture_Guide-Technical_Users_Provided_and_Required_by_Satellite" class="tableblock frame-all grid-all stretch">
<caption class="title">Table 1. Technical Users Provided and Required by orcharhino</caption>
<colgroup>
<col style="width: 14.2857%;">
<col style="width: 14.2857%;">
<col style="width: 14.2857%;">
<col style="width: 14.2857%;">
<col style="width: 14.2857%;">
<col style="width: 14.2857%;">
<col style="width: 14.2858%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">User name</th>
<th class="tableblock halign-left valign-top">UID</th>
<th class="tableblock halign-left valign-top">Group name</th>
<th class="tableblock halign-left valign-top">GID</th>
<th class="tableblock halign-left valign-top">Flexible UID and GID</th>
<th class="tableblock halign-left valign-top">Home</th>
<th class="tableblock halign-left valign-top">Shell</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">foreman</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N/A</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">foreman</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N/A</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">/usr/share/foreman</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">/sbin/nologin</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">foreman-proxy</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N/A</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">foreman-proxy</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N/A</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">/usr/share/foreman-proxy</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">/sbin/nologin</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">puppet</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N/A</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">puppet</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N/A</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">/opt/puppetlabs/server/data/puppetserver</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">/sbin/nologin</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">qdrouterd</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N/A</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">qdrouterd</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N/A</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N/A</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">/sbin/nologin</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">qpidd</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N/A</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">qpidd</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N/A</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">/var/lib/qpidd</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">/sbin/nologin</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">unbound</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N/A</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">unbound</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N/A</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">/etc/unbound</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">/sbin/nologin</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">postgres</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">26</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">postgres</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">26</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">/var/lib/pgsql</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">/bin/bash</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">apache</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">48</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">apache</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">48</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">/usr/share/httpd</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">/sbin/nologin</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tomcat</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">53</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tomcat</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">53</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">/usr/share/tomcat</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">/bin/nologin</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">saslauth</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N/A</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">saslauth</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">76</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N/A</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">/sbin/nologin</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect1">
<h2 id="appe-Red_Hat_Satellite-Architecture_Guide-Glossary_of_Terms">Appendix B: Glossary of Terms</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This glossary documents various terms used in relation to orcharhino.</p>
</div>
<div id="varl-Glossary_of_Terms-Activation_Key" class="dlist">
<dl>
<dt class="hdlist1"><strong>Activation Key</strong></dt>
<dd>
<p>A token for host registration and subscription attachment.
Activation keys define subscriptions, products, content views, and other parameters to be associated with a newly created host.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Answer_File" class="dlist">
<dl>
<dt class="hdlist1"><strong>Answer File</strong></dt>
<dd>
<p>A configuration file that defines settings for an installation scenario.
Answer files are defined in the YAML format and stored in the <strong>/etc/foreman-installer/scenarios.d/</strong> directory.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-ARF_Report" class="dlist">
<dl>
<dt class="hdlist1"><strong>ARF Report</strong></dt>
<dd>
<p>The result of an OpenSCAP audit.
Summarizes the security compliance of hosts managed by orcharhino.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Audits" class="dlist">
<dl>
<dt class="hdlist1"><strong>Audits</strong></dt>
<dd>
<p>Provide a report on changes made by a specific user.
Audits can be viewed in the orcharhino web UI under <strong>Monitor</strong> &gt; <strong>Audits</strong>.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-BMC" class="dlist">
<dl>
<dt class="hdlist1"><strong>Baseboard Management Controller (BMC)</strong></dt>
<dd>
<p>Enables remote power management of bare-metal hosts.
In orcharhino, you can create a BMC interface to manage selected hosts.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Bootdisk" class="dlist">
<dl>
<dt class="hdlist1"><strong>Boot Disk</strong></dt>
<dd>
<p>An ISO image used for PXE-less provisioning.
This ISO enables the host to connect to orcharhino server, boot the installation media, and install the operating system.
There are several kinds of boot disks: <strong>host image</strong>, <strong>full host image</strong>, <strong>generic image</strong>, and <strong>subnet image</strong>.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Capsule" class="dlist">
<dl>
<dt class="hdlist1"><strong>orcharhino Proxy (orcharhino Proxy)</strong></dt>
<dd>
<p>An additional server that can be used in a orcharhino deployment to facilitate content federation and distribution (act as a Pulp mirror), and to run other localized services (Puppet Master, <strong>DHCP</strong>, <strong>DNS</strong>, <strong>TFTP</strong>, and more).
orcharhino Proxies are useful for orcharhino deployment across various geographical locations.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Catalog" class="dlist">
<dl>
<dt class="hdlist1"><strong>Catalog</strong></dt>
<dd>
<p>A document that describes the desired system state for one specific host managed by Puppet.
It lists all of the resources that need to be managed, as well as any dependencies between those resources.
Catalogs are compiled by a Puppet Master from Puppet Manifests and data from Puppet Agents.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Candlepin" class="dlist">
<dl>
<dt class="hdlist1"><strong>Candlepin</strong></dt>
<dd>
<p>A service within Katello responsible for subscription management.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Compliance_Policy" class="dlist">
<dl>
<dt class="hdlist1"><strong>Compliance Policy</strong></dt>
<dd>
<p>Refers to a scheduled task executed on orcharhino server that checks the specified hosts for compliance against SCAP content.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Compute_Profile" class="dlist">
<dl>
<dt class="hdlist1"><strong>Compute Profile</strong></dt>
<dd>
<p>Specifies default attributes for new virtual machines on a compute resource.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Compute_Resource" class="dlist">
<dl>
<dt class="hdlist1"><strong>Compute Resource</strong></dt>
<dd>
<p>A virtual or cloud infrastructure, which orcharhino uses for deployment of hosts and systems.
Examples include oVirt, OpenStack, EC2, and VMWare.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Container" class="dlist">
<dl>
<dt class="hdlist1"><strong>Container (Docker Container)</strong></dt>
<dd>
<p>An isolated application sandbox that contains all runtime dependencies required by an application.
orcharhino supports container provisioning on a dedicated compute resource.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Container_Image" class="dlist">
<dl>
<dt class="hdlist1"><strong>Container Image</strong></dt>
<dd>
<p>A static snapshot of the container’s configuration.
orcharhino supports various methods of importing container images as well as distributing images to hosts through content views.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Content" class="dlist">
<dl>
<dt class="hdlist1"><strong>Content</strong></dt>
<dd>
<p>A general term for everything orcharhino distributes to hosts.
Includes software packages (RPM files), or Docker images.
Content is synchronized into the Library and then promoted into life cycle environments using content views so that they can be consumed by hosts.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Content_Delivery_Network_CDN" class="dlist">
<dl>
<dt class="hdlist1"><strong>Content Delivery Network (CDN)</strong></dt>
<dd>
<p>The mechanism used to deliver Red&#160;Hat content to orcharhino server.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Content_Host" class="dlist">
<dl>
<dt class="hdlist1"><strong>Content Host</strong></dt>
<dd>
<p>The part of a host that manages tasks related to content and subscriptions.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Content_View" class="dlist">
<dl>
<dt class="hdlist1"><strong>Content View</strong></dt>
<dd>
<p>A subset of Library content created by intelligent filtering.
Once a content view is published, it can be promoted through the life cycle environment path, or modified using incremental upgrades.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Discovered_Host" class="dlist">
<dl>
<dt class="hdlist1"><strong>Discovered Host</strong></dt>
<dd>
<p>A bare-metal host detected on the provisioning network by the Discovery plug-in.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Discovery_Image" class="dlist">
<dl>
<dt class="hdlist1"><strong>Discovery Image</strong></dt>
<dd>
<p>Refers to the minimal operating system based on Red Hat Enterprise Linux that is PXE-booted on hosts to acquire initial hardware information and to communicate with orcharhino server before starting the provisioning process.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Discovery_Plug-in" class="dlist">
<dl>
<dt class="hdlist1"><strong>Discovery Plug-in</strong></dt>
<dd>
<p>Enables automatic bare-metal discovery of unknown hosts on the provisioning network.
The plug-in consists of three components: services running on orcharhino server and orcharhino Proxy, and the Discovery image running on host.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Discovery_Rule" class="dlist">
<dl>
<dt class="hdlist1"><strong>Discovery Rule</strong></dt>
<dd>
<p>A set of predefined provisioning rules which assigns a host group to discovered hosts and triggers provisioning automatically.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Docker_Tag" class="dlist">
<dl>
<dt class="hdlist1"><strong>Docker Tag</strong></dt>
<dd>
<p>A mark used to differentiate container images, typically by the version of the application stored in the image.
In the orcharhino web UI, you can filter images by tag under <strong>Content</strong> &gt; <strong>Docker Tags</strong>.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-ERB" class="dlist">
<dl>
<dt class="hdlist1"><strong>ERB</strong></dt>
<dd>
<p>Embedded Ruby (ERB) is a template syntax used in provisioning and job templates.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Errata" class="dlist">
<dl>
<dt class="hdlist1"><strong>Errata</strong></dt>
<dd>
<p>Updated RPM packages containing security fixes, bug fixes, and enhancements.
In relationship to a host, erratum is <strong>applicable</strong> if it updates a package installed on the host and <strong>installable</strong> if it is present in the host&#8217;s content view (which means it is accessible for installation on the host).</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-External_Node_Classifier" class="dlist">
<dl>
<dt class="hdlist1"><strong>External Node Classifier</strong></dt>
<dd>
<p>A construct that provides additional data for a server to use when configuring hosts.
orcharhino acts as an External Node Classifier to Puppet servers in a orcharhino deployment.</p>
<div class="paragraph">
<p>Note that the External Node Classifier will be removed in the next orcharhino version.</p>
</div>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Facter" class="dlist">
<dl>
<dt class="hdlist1"><strong>Facter</strong></dt>
<dd>
<p>A program that provides information (facts) about the system on which it is run; for example, Facter can report total memory, operating system version, architecture, and more.
Puppet modules enable specific configurations based on host data gathered by Facter.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Facts" class="dlist">
<dl>
<dt class="hdlist1"><strong>Facts</strong></dt>
<dd>
<p>Host parameters such as total memory, operating system version, or architecture.
Facts are reported by Facter and used by Puppet.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Foreman" class="dlist">
<dl>
<dt class="hdlist1"><strong>Foreman</strong></dt>
<dd>
<p>The component mainly responsible for provisioning and content life cycle management.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-satellite-maintain_Services" class="dlist">
<dl>
<dt class="hdlist1"><strong>foreman-maintain services</strong></dt>
<dd>
<p>A set of services that orcharhino server and orcharhino Proxys use for operation.
You can use the <code>foreman-maintain</code> tool to manage these services.
To see the full list of services, enter the <code>foreman-maintain service list</code> command on the machine where orcharhino or orcharhino Proxy is installed.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Foreman_Hooks" class="dlist">
<dl>
<dt class="hdlist1"><strong>Foreman Hook</strong></dt>
<dd>
<p>An executable that is automatically triggered when an orchestration event occurs, such as when a host is created or when provisioning of a host has completed.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Full_Host_Image" class="dlist">
<dl>
<dt class="hdlist1"><strong>Full Host Image</strong></dt>
<dd>
<p>A boot disk used for PXE-less provisioning of a specific host.
The full host image contains an embedded Linux kernel and init RAM disk of the associated operating system installer.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Generic_Image" class="dlist">
<dl>
<dt class="hdlist1"><strong>Generic Image</strong></dt>
<dd>
<p>A boot disk for PXE-less provisioning that is not tied to a specific host.
The generic image sends the host’s MAC address to orcharhino server, which matches it against the host entry.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Hammer" class="dlist">
<dl>
<dt class="hdlist1"><strong>Hammer</strong></dt>
<dd>
<p>A command line tool for managing orcharhino.
You can execute Hammer commands from the command line or utilize them in scripts.
Hammer also provides an interactive shell.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Host" class="dlist">
<dl>
<dt class="hdlist1"><strong>Host</strong></dt>
<dd>
<p>Refers to any system, either physical or virtual, that orcharhino manages.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Host_Collection" class="dlist">
<dl>
<dt class="hdlist1"><strong>Host Collection</strong></dt>
<dd>
<p>A user defined group of one or more Hosts used for bulk actions such as errata installation.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Host_Group" class="dlist">
<dl>
<dt class="hdlist1"><strong>Host Group</strong></dt>
<dd>
<p>A template for building a host.
Host groups hold shared parameters, such as subnet or life cycle environment, that are inherited by host group members.
Host groups can be nested to create a hierarchical structure.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Host_Image" class="dlist">
<dl>
<dt class="hdlist1"><strong>Host Image</strong></dt>
<dd>
<p>A boot disk used for PXE-less provisioning of a specific host.
The host image only contains the boot files necessary to access the installation media on orcharhino server.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Incremental_Update" class="dlist">
<dl>
<dt class="hdlist1"><strong>Incremental Upgrade (of a Content View)</strong></dt>
<dd>
<p>The act of creating a new (minor) content view version in a life cycle environment.
Incremental upgrades provide a way to make in-place modification of an already published content view.
Useful for rapid updates, for example when applying security errata.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Job" class="dlist">
<dl>
<dt class="hdlist1"><strong>Job</strong></dt>
<dd>
<p>A command executed remotely on a host from orcharhino server.
Every job is defined in a job template.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Job_Template" class="dlist">
<dl>
<dt class="hdlist1"><strong>Job Template</strong></dt>
<dd>
<p>Defines properties of a job.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Katello" class="dlist">
<dl>
<dt class="hdlist1"><strong>Katello</strong></dt>
<dd>
<p>A Foreman plug-in responsible for subscription and repository management.</p>
</dd>
<dt class="hdlist1"><strong>Lazy Sync</strong></dt>
<dd>
<p>The ability to change a <code>yum</code> repository&#8217;s default download policy of <strong>Immediate</strong> to <strong>On Demand</strong>.
The <strong>On Demand</strong> setting saves storage space and synchronization time by only downloading the packages when requested by a client.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Location" class="dlist">
<dl>
<dt class="hdlist1"><strong>Location</strong></dt>
<dd>
<p>A collection of default settings that represent a physical place.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Library" class="dlist">
<dl>
<dt class="hdlist1"><strong>Library</strong></dt>
<dd>
<p>A container for content from all synchronized repositories on orcharhino server.
Libraries exist by default for each organization as the root of every life cycle environment path and the source of content for every content view.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Life_Cycle_Environment" class="dlist">
<dl>
<dt class="hdlist1"><strong>Life Cycle Environment</strong></dt>
<dd>
<p>A container for content view versions consumed by the content hosts.
A Life Cycle Environment represents a step in the life cycle environment path.
Content moves through life cycle environments by publishing and promoting content views.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Life_Cycle_Environment_Path" class="dlist">
<dl>
<dt class="hdlist1"><strong>Life Cycle Environment Path</strong></dt>
<dd>
<p>A sequence of life cycle environments through which the content views are promoted.
You can promote a content view through a typical promotion path; for example, from development to test to production.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Manifest" class="dlist">
<dl>
<dt class="hdlist1"><strong>Manifest (Subscription Manifest)</strong></dt>
<dd>
<p>A mechanism for transferring subscriptions from the Red&#160;Hat Customer Portal to orcharhino.
Do not confuse with <a href="#varl-Glossary_of_Terms-Puppet_Manifest">Puppet Manifest</a>.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-OpenSCAP" class="dlist">
<dl>
<dt class="hdlist1"><strong>OpenSCAP</strong></dt>
<dd>
<p>A project implementing security compliance auditing according to the Security Content Automation Protocol (SCAP).
OpenSCAP is integrated in orcharhino to provide compliance auditing for managed hosts.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Organization" class="dlist">
<dl>
<dt class="hdlist1"><strong>Organization</strong></dt>
<dd>
<p>An isolated collection of systems, content, and other functionality within a orcharhino deployment.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Parameters" class="dlist">
<dl>
<dt class="hdlist1"><strong>Parameter</strong></dt>
<dd>
<p>Defines the behavior of orcharhino components during provisioning.
Depending on the parameter scope, we distinguish between global, domain, host group, and host parameters.
Depending on the parameter complexity, we distinguish between simple parameters (key-value pair) and smart parameters (conditional arguments, validation, overrides).</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Parametrized_Class" class="dlist">
<dl>
<dt class="hdlist1"><strong>Parametrized Class (Smart Class Parameter)</strong></dt>
<dd>
<p>A parameter created by importing a class from Puppet Master.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Permission" class="dlist">
<dl>
<dt class="hdlist1"><strong>Permission</strong></dt>
<dd>
<p>Defines an action related to a selected part of orcharhino infrastructure (resource type).
Each resource type is associated with a set of permissions, for example the <strong>Architecture</strong> resource type has the following permissions: <strong>view_architectures</strong>, <strong>create_architectures</strong>, <strong>edit_architectures</strong>, and <strong>destroy_architectures</strong>.
You can group permissions into roles and associate them with users or user groups.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Product" class="dlist">
<dl>
<dt class="hdlist1"><strong>Product</strong></dt>
<dd>
<p>A collection of content repositories.
Products are either provided by Red&#160;Hat CDN or created by the orcharhino administrator to group custom repositories.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Promote" class="dlist">
<dl>
<dt class="hdlist1"><strong>Promote (a Content View)</strong></dt>
<dd>
<p>The act of moving a content view from one life cycle environment to another.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Provisioning_Template" class="dlist">
<dl>
<dt class="hdlist1"><strong>Provisioning Template</strong></dt>
<dd>
<p>Defines host provisioning settings.
Provisioning templates can be associated with host groups, life cycle environments, or operating systems.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Publish" class="dlist">
<dl>
<dt class="hdlist1"><strong>Publish (a Content View)</strong></dt>
<dd>
<p>The act of making a content view version available in a life cycle environment and usable by hosts.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Pulp" class="dlist">
<dl>
<dt class="hdlist1"><strong>Pulp</strong></dt>
<dd>
<p>A service within Katello responsible for repository and content management.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Pulp_Mirror" class="dlist">
<dl>
<dt class="hdlist1"><strong>Pulp Mirror</strong></dt>
<dd>
<p>A orcharhino Proxy component that mirrors content.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Puppet" class="dlist">
<dl>
<dt class="hdlist1"><strong>Puppet</strong></dt>
<dd>
<p>The configuration management component of orcharhino.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Puppet_Agent" class="dlist">
<dl>
<dt class="hdlist1"><strong>Puppet Agent</strong></dt>
<dd>
<p>A service running on a host that applies configuration changes to that host.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Puppet_Environment" class="dlist">
<dl>
<dt class="hdlist1"><strong>Puppet Environment</strong></dt>
<dd>
<p>An isolated set of Puppet Agent nodes that can be associated with a specific set of Puppet Modules.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Puppet_Manifest" class="dlist">
<dl>
<dt class="hdlist1"><strong>Puppet Manifest</strong></dt>
<dd>
<p>Refers to Puppet scripts, which are files with the <strong>.pp</strong> extension.
The files contain code to define a set of necessary resources, such as packages, services, files, users and groups, and so on, using a set of key-value pairs for their attributes.</p>
<div class="paragraph">
<p>Do not confuse with <a href="#varl-Glossary_of_Terms-Manifest">Manifest (Subscription Manifest)</a>.</p>
</div>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Puppet_Master" class="dlist">
<dl>
<dt class="hdlist1"><strong>Puppet Master</strong></dt>
<dd>
<p>A orcharhino Proxy component that provides Puppet Manifests to hosts for execution by the Puppet Agent.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Puppet_Module" class="dlist">
<dl>
<dt class="hdlist1"><strong>Puppet Module</strong></dt>
<dd>
<p>A self-contained bundle of code (Puppet Manifests) and data (facts) that you can use to manage resources such as users, files, and services.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Recurring_Logic" class="dlist">
<dl>
<dt class="hdlist1"><strong>Recurring Logic</strong></dt>
<dd>
<p>A job executed automatically according to a schedule.
In the orcharhino web UI, you can view those jobs under <strong>Monitor</strong> &gt; <strong>Recurring logics</strong>.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Registry" class="dlist">
<dl>
<dt class="hdlist1"><strong>Registry</strong></dt>
<dd>
<p>An archive of container images.
orcharhino supports importing images from local and external registries.
orcharhino itself can act as an image registry for hosts.
However, hosts cannot push changes back to the registry.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Repository" class="dlist">
<dl>
<dt class="hdlist1"><strong>Repository</strong></dt>
<dd>
<p>Provides storage for a collection of content.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Resource_type" class="dlist">
<dl>
<dt class="hdlist1"><strong>Resource Type</strong></dt>
<dd>
<p>Refers to a part of orcharhino infrastructure, for example host, capsule, or architecture.
Used in permission filtering.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Role" class="dlist">
<dl>
<dt class="hdlist1"><strong>Role</strong></dt>
<dd>
<p>Specifies a collection of permissions that are applied to a set of resources, such as hosts.
Roles can be assigned to users and user groups.
orcharhino provides a number of predefined roles.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-SCAP_Content" class="dlist">
<dl>
<dt class="hdlist1"><strong>SCAP content</strong></dt>
<dd>
<p>A file containing the configuration and security baseline against which hosts are checked.
Used in compliance policies.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Scenario" class="dlist">
<dl>
<dt class="hdlist1"><strong>Scenario</strong></dt>
<dd>
<p>A set of predefined settings for the orcharhino CLI installer.
Scenario defines the type of installation, for example to install orcharhino Proxy execute <code>orcharhino-installer --no-enable-foreman</code>.
Every scenario has its own answer file to store the scenario settings.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Smart_Proxy" class="dlist">
<dl>
<dt class="hdlist1"><strong>Smart Proxy</strong></dt>
<dd>
<p>A orcharhino Proxy component that can integrate with external services, such as <strong>DNS</strong> or <strong>DHCP</strong>.
In upstream Foreman terminology, Smart Proxy is a synonym of orcharhino Proxy.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Smart_Variable" class="dlist">
<dl>
<dt class="hdlist1"><strong>Smart Variable</strong></dt>
<dd>
<p>A configuration value used by classes in Puppet modules.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Standard_Operating_Environment_SOE" class="dlist">
<dl>
<dt class="hdlist1"><strong>Standard Operating Environment (SOE)</strong></dt>
<dd>
<p>A controlled version of the operating system on which applications are deployed.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Subnet_Image" class="dlist">
<dl>
<dt class="hdlist1"><strong>Subnet Image</strong></dt>
<dd>
<p>A type of generic image for PXE-less provisioning that communicates through orcharhino Proxy.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Subscription" class="dlist">
<dl>
<dt class="hdlist1"><strong>Subscription</strong></dt>
<dd>
<p>An entitlement for receiving content and service from Red&#160;Hat.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Synchronization" class="dlist">
<dl>
<dt class="hdlist1"><strong>Synchronization</strong></dt>
<dd>
<p>Refers to mirroring content from external resources into the orcharhino Library.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Synchronization_Plans" class="dlist">
<dl>
<dt class="hdlist1"><strong>Synchronization Plan</strong></dt>
<dd>
<p>Provides scheduled execution of content synchronization.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Task" class="dlist">
<dl>
<dt class="hdlist1"><strong>Task</strong></dt>
<dd>
<p>A background process executed on the orcharhino or orcharhino Proxy, such as repository synchronization or content view publishing.
You can monitor the task status in the orcharhino web UI under <strong>Monitor</strong> &gt; <strong>Tasks</strong>.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-Trend" class="dlist">
<dl>
<dt class="hdlist1"><strong>Trend</strong></dt>
<dd>
<p>A means of tracking changes in specific parts of orcharhino infrastructure.
Configure trends in orcharhino web UI under <strong>Monitor</strong> &gt; <strong>Trends</strong>.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-User_Group" class="dlist">
<dl>
<dt class="hdlist1"><strong>User Group</strong></dt>
<dd>
<p>A collection of roles which can be assigned to a collection of users.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-User" class="dlist">
<dl>
<dt class="hdlist1"><strong>User</strong></dt>
<dd>
<p>Anyone registered to use orcharhino.
Authentication and authorization is possible through built-in logic, through external resources (LDAP, Identity Management, or Active Directory), or with Kerberos.</p>
</dd>
</dl>
</div>
<div id="varl-Glossary_of_Terms-virt-who" class="dlist">
<dl>
<dt class="hdlist1"><strong>virt-who</strong></dt>
<dd>
<p>An agent for retrieving IDs of virtual machines from the hypervisor.
When used with orcharhino, virt-who reports those IDs to orcharhino server so that it can provide subscriptions for hosts provisioned on virtual machines.</p>
</dd>
</dl>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Version 2.1.3 (unsupported)<br>
Last updated Dec 2022
</div>
</div>
</body>
</html>